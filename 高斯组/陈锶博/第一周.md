# 示例

# 第一周

## 第一次记录

3dgs类代码
class GaussianModel:

    def setup_functions(self):
        def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):
            L = build_scaling_rotation(scaling_modifier * scaling, rotation)
            actual_covariance = L @ L.transpose(1, 2)
            symm = strip_symmetric(actual_covariance)
            return symm
        
        self.scaling_activation = torch.exp
        self.scaling_inverse_activation = torch.log

        self.covariance_activation = build_covariance_from_scaling_rotation

        self.opacity_activation = torch.sigmoid
        self.inverse_opacity_activation = inverse_sigmoid

        self.rotation_activation = torch.nn.functional.normalize


    def __init__(self, sh_degree, optimizer_type="default"):
        self.active_sh_degree = 0
        self.optimizer_type = optimizer_type
        self.max_sh_degree = sh_degree  
        self._xyz = torch.empty(0)
        self._features_dc = torch.empty(0)
        self._features_rest = torch.empty(0)
        self._scaling = torch.empty(0)
        self._rotation = torch.empty(0)
        self._opacity = torch.empty(0)
        self.max_radii2D = torch.empty(0)
        self.xyz_gradient_accum = torch.empty(0)
        self.denom = torch.empty(0)
        self.optimizer = None
        self.percent_dense = 0
        self.spatial_lr_scale = 0
        self.setup_functions()

    def capture(self):
        return (
            self.active_sh_degree,
            self._xyz,
            self._features_dc,
            self._features_rest,
            self._scaling,
            self._rotation,
            self._opacity,
            self.max_radii2D,
            self.xyz_gradient_accum,
            self.denom,
            self.optimizer.state_dict(),
            self.spatial_lr_scale,
        )

    def restore(self, model_args, training_args):
        (self.active_sh_degree, 
        self._xyz, 
        self._features_dc, 
        self._features_rest,
        self._scaling, 
        self._rotation, 
        self._opacity,
        self.max_radii2D, 
        xyz_gradient_accum, 
        denom,
        opt_dict, 
        self.spatial_lr_scale) = model_args
        self.training_setup(training_args)
        self.xyz_gradient_accum = xyz_gradient_accum
        self.denom = denom
        self.optimizer.load_state_dict(opt_dict)

def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):构建协方差矩阵，先构建缩放矩阵L，再actual_covariance = L @ L.transpose(1, 2)计算协方差，分别传入的是缩放，缩放修正和旋转

接着就是指数函数用exp（x）为e的x次幂，保证缩放因子为正。

self.opacity_activation = torch.sigmoid，透明度[0,1]

上面的每一个运算都有逆运算

self.rotation_activation = torch.nn.functional.normalize,归一化函数，保持旋转四元数为单位四元数


下面是--init--
self.active_sh_degree = 0和self.max_sh_degree = sh_degree是球谐函数的最大阶和当前阶

self._xyz = torch.empty(0)，高斯的位置，用torch当前0阶作为参数，实际情况会变成传入的【N,3】矩阵，下面同样

self._features_dc = torch.empty(0) 球谐函数DC分量，表示基础颜色，【N,3】一般为（R，G,B）

self._features_rest = torch.empty(0) 球谐函数高频分量，根据最高阶来描述视角依赖的颜色变化为【N,(max_sh*max_sh -1)*3】，捕捉镜面反射、光泽效果，例如一阶的话是线性变化，二阶是二次变化

self._scaling = torch.empty(0)缩放参数[N，3]，控制高斯椭球在各轴的大小，决定协方差矩阵的特征值，形成缩放矩阵

self._rotation = torch.empty(0)旋转四元数[N, 4]，控制高斯椭球的方向，并且决定协方差矩阵的特征向量，高斯方向如果对着相机就是高贡献，背对即为低贡献

self._opacity = torch.empty(0)透明度参数[N,1]控制高斯点的可见性

self.max_radii2D = torch.empty(0)，最大2d投影半径，表示高斯点在图像平面上的覆盖范围，可以在渲染前用于剔除对当前视图贡献小的高斯点

self.xyz_gradient_accum = torch.empty(0) 位置梯度累积，[N, 3]对每个高斯点的xyz梯度累积

self.denom = torch.empty(0) 自适应过程中的分母项，每个高斯点一个值

self.optimizer = None 优化器

self.percent_dense = 0密集度百分比可以控制高斯点分裂或者克隆的强度，为【0，1】一般为0.01，前x%的高斯点，x为precent——dense,在自适应过程中的检查

self.spatial_lr_scale = 0 空间学习率缩放因子 根据高斯点对角线在背景的尺寸比例，消除场景尺寸对学习率的影响，防止大场景中小学习率导致收敛慢，小场景中大学习率导致震荡，学习率控制着模型在训练过程中更新权重的步长大小

def capture(self):
    return (
        self.active_sh_degree,
        self._xyz,
        self._features_dc,
        self._features_rest,
        self._scaling,
        self._rotation,
        self._opacity,
        self.max_radii2D,
        self.xyz_gradient_accum,
        self.denom,
        self.optimizer.state_dict(),  # 优化器状态
        self.spatial_lr_scale,
    )返回元组的状态，即作为一个接口获取传入元组的所有参数，用于保存检查点

def restore(self, model_args, training_args):
    (self.active_sh_degree, 
     self._xyz, 
     self._features_dc, 
     self._features_rest,
     self._scaling, 
     self._rotation, 
     self._opacity,
     self.max_radii2D, 
     xyz_gradient_accum, 
     denom,
     opt_dict, 
     self.spatial_lr_scale) = model_args
     
    self.training_setup(training_args)
    
    # 恢复优化状态
    self.xyz_gradient_accum = xyz_gradient_accum
    self.denom = denom
    self.optimizer.load_state_dict(opt_dict)
    ）实现训练中断后继续训练，先加载保存的模型状态，调用 training_setup 重新初始化优化器，然后恢复梯度累积等优化状态变量

## 第二次记录

下面是@property 装饰器定义，封装内部状态，提供一致接口，并且支持自动微分
    @property
    def get_scaling(self):获取激活后的缩放参数
        return self.scaling_activation(self._scaling)激活原始的参数
    
    @property
    def get_rotation(self):获取归一化后的旋转四元数
        return self.rotation_activation(self._rotation)
    
    @property
    def get_xyz(self):直接获取位置坐标
        return self._xyz
    
    @property
    def get_features(self):获取所有球谐系数
        features_dc = self._features_dc
        features_rest = self._features_rest
        return torch.cat((features_dc, features_rest), dim=1)用cat动态拼接DC和高阶分量
    
    @property
    def get_features_dc(self):获取球谐DC分量
        return self._features_dc
    
    @property
    def get_features_rest(self):获取球谐高阶分量
        return self._features_rest
    
    @property
    def get_opacity(self):获取激活后的不透明度
        return self.opacity_activation(self._opacity)
    
    @property
    def get_exposure(self):获取相机曝光参数，形状[N_cam, 3, 4]
        return self._exposure

def get_exposure_from_name(self, image_name):##曝光处理，获取特定图像的曝光参数

    if self.pretrained_exposures is None:##未训练
    
        return self._exposure[self.exposure_mapping[image_name]]#图像名称到参数索引的映射字典
    else:#预训练
    
        return self.pretrained_exposures[image_name]


def get_covariance(self, scaling_modifier = 1):##计算协方差矩阵

        return self.covariance_activation(self.get_scaling, scaling_modifier, self._rotation)


def oneupSHdegree(self):##提升球谐函数阶数，渐进式学习，先颜色，再反射，接着精细的反射

    if self.active_sh_degree < self.max_sh_degree:
    
        self.active_sh_degree += 1


def create_from_pcd(self, pcd : BasicPointCloud, cam_infos : int, spatial_lr_scale : float):点云初始化3D高斯模型
        self.spatial_lr_scale = spatial_lr_scale空间缩放
        fused_point_cloud = torch.tensor(np.asarray(pcd.points)).float().cuda()位置初始化，将点云位置转换为CUDA张量，np.asarray：转换为NumPy数组，torch.tensor：创建PyTorch张量，float()：转换为浮点类型，cuda()：移至GPU
        
        fused_color = RGB2SH(torch.tensor(np.asarray(pcd.colors)).float().cuda())将RGB转为球谐DC分量
        
        features = torch.zeros((fused_color.shape[0], 3, (self.max_sh_degree + 1) ** 2)).float().cuda()创建全零球谐系数张量
        
        features[:, :3, 0 ] = fused_color 将球谐DC分量放入第一个系数槽
        features[:, 3:, 1:] = 0.0 初始化所有高阶球谐系数为0

        print("Number of points at initialisation : ", fused_point_cloud.shape[0])

        dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)基于点间距计算初始缩放，在GPU上并行计算点间距，返回每个点的最小距离平方
        
        scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3) 缩放参数初始化，torch.log()：取对数 → 优化空间，[...,None]：增加维度 [N,1]，repeat(1,3)：复制到三个轴 [N,3]
        
        rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")初始化旋转四元数
        rots[:, 0] = 1 [1,0,0,0]

        opacities = self.inverse_opacity_activation(0.1 * torch.ones((fused_point_cloud.shape[0], 1), dtype=torch.float, device="cuda"))初始化透明度参数，创建全0.1张量 [N,1]，应用逆sigmoid

        self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True))将位置设为可训练参数，nn.Parameter 标记为模型参数，requires_grad_(True) 启用梯度
        
        self._features_dc = nn.Parameter(features[:,:,0:1].transpose(1, 2).contiguous().requires_grad_(True))注册球谐DC分量参数，切片获取DC分量 [N,3,1]，transpose(1,2) → [N,1,3]，contiguous() 确保内存连续
        
        self._features_rest = nn.Parameter(features[:,:,1:].transpose(1, 2).contiguous().requires_grad_(True))注册球谐高阶分量参数，[:,:,1:] 获取1阶及以上系数
        
        self._scaling = nn.Parameter(scales.requires_grad_(True))注册缩放参数，存储缩放后的对数值
        
        self._rotation = nn.Parameter(rots.requires_grad_(True))注册旋转四元数参数
        
        self._opacity = nn.Parameter(opacities.requires_grad_(True))注册透明度参数，存储逆simoid的值
        
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")初始化2D投影半径为0
        
        self.exposure_mapping = {cam_info.image_name: idx for idx, cam_info in enumerate(cam_infos)}创建图像名到曝光参数索引的映射
        self.pretrained_exposures = None 标记无预训练曝光参数
        
        exposure = torch.eye(3, 4, device="cuda")[None].repeat(len(cam_infos), 1, 1)初始化曝光参数矩阵[N, 3, 4]
        
        self._exposure = nn.Parameter(exposure.requires_grad_(True))注册可学习的曝光参数


def training_setup(self, training_args):
        self.percent_dense = training_args.percent_dense设置密集度百分比，从训练参数获取密集度百分比值
        
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")创建并归零位置梯度累积张量，记录每个高斯点位置梯度的累积量
        
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")创建并归零分母项张量，记录每个高斯点的更新次数

        l = [
            {'params': [self._xyz], 'lr': training_args.position_lr_init * self.spatial_lr_scale, "name": "xyz"},
            {'params': [self._features_dc], 'lr': training_args.feature_lr, "name": "f_dc"},
            {'params': [self._features_rest], 'lr': training_args.feature_lr / 20.0, "name": "f_rest"},
            {'params': [self._opacity], 'lr': training_args.opacity_lr, "name": "opacity"},
            {'params': [self._scaling], 'lr': training_args.scaling_lr, "name": "scaling"},
            {'params': [self._rotation], 'lr': training_args.rotation_lr, "name": "rotation"}
        ]定义优化参数组，应用空间缩放因子，同时SH高频分量20倍降速降低学习率防止过拟合

        if self.optimizer_type == "default":
            self.optimizer = torch.optim.Adam(l, lr=0.0, eps=1e-15)default (Adam），标准Adam优化器，通用场景
        elif self.optimizer_type == "sparse_adam":为稀疏梯度定制，大型场景(>100万高斯点)
            try:
                self.optimizer = SparseGaussianAdam(l, lr=0.0, eps=1e-15)
            except:
                # A special version of the rasterizer is required to enable sparse adam
                self.optimizer = torch.optim.Adam(l, lr=0.0, eps=1e-15)

        self.exposure_optimizer = torch.optim.Adam([self._exposure])为曝光参数单独创建优化器，避免主优化器的干扰

        self.xyz_scheduler_args = get_expon_lr_func(lr_init=training_args.position_lr_init*self.spatial_lr_scale,
                                                    lr_final=training_args.position_lr_final*self.spatial_lr_scale,
                                                    lr_delay_mult=training_args.position_lr_delay_mult,
                                                    max_steps=training_args.position_lr_max_steps)位置学习率调度配置，初始学习率，最终学习率，延迟衰减因子，最大步数
        
        self.exposure_scheduler_args = get_expon_lr_func(training_args.exposure_lr_init, training_args.exposure_lr_final,
                                                        lr_delay_steps=training_args.exposure_lr_delay_steps,独立设置，曝光可能需要更早调整
                                                        lr_delay_mult=training_args.exposure_lr_delay_mult,
                                            全程调整曝光 max_steps=training_args.iterations)曝光学习率调度配置


## 第三次记录
def construct_list_of_attributes(self):
    l = ['x', 'y', 'z', 'nx', 'ny', 'nz']基础几何数据，nx，ny，nz是法线
    
    for i in range(self._features_dc.shape[1]*self._features_dc.shape[2]):self._features_dc 是形状为 (N, 1, 3) 的张量，1 * 3 = 3，生成f_dc_0, f_dc_1, f_dc_2，对应RGB三个颜色通道的基色分量
        l.append('f_dc_{}'.format(i))
    
    for i in range(self._features_rest.shape[1]*self._features_rest.shape[2]):self._features_rest 是形状为 (N, 15, 3) 的张量，循环次数 = 15 * 3 = 45
        l.append('f_rest_{}'.format(i))
    
    l.append('opacity')添加透明度
    
    for i in range(self._scaling.shape[1]):缩放三个分量
        l.append('scale_{}'.format(i))
    
    for i in range(self._rotation.shape[1]):旋转四个分量
        l.append('rot_{}'.format(i))
    
    return l


def save_ply(self, path):全流程为PyTorch张量变成CPU NumPy数组，再变成结构化数组，再变成PLY元素，最后变成PLY文件
        mkdir_p(os.path.dirname(path))

        xyz = self._xyz.detach().cpu().numpy()  detach()：从计算图中分离，避免梯度计算
        
        normals = np.zeros_like(xyz)初始化法线数据，创建与位置数组相同形状的全零数组，暂时用零填充
        
        f_dc = self._features_dc.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()   transpose(1, 2)：交换维度 → (N, 3, 1)，flatten(start_dim=1)从第1维展平 → (N, 3)
        
        f_rest = self._features_rest.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()  transpose(1, 2) → (N, 3, 15)  flatten(start_dim=1) → (N, 45) 3x15=45
        
        opacities = self._opacity.detach().cpu().numpy()

        scale = self._scaling.detach().cpu().numpy()提取缩放参数(N, 3)
        
        rotation = self._rotation.detach().cpu().numpy()提取旋转参数,(N, 4)

        dtype_full = [(attribute, 'f4') for attribute in self.construct_list_of_attributes()]  调用之前定义的construct_list_of_attributes()获取属性列表

        elements = np.empty(xyz.shape[0], dtype=dtype_full)创建空的结构化数组：
        
        attributes = np.concatenate((xyz, normals, f_dc, f_rest, opacities, scale, rotation), axis=1)合并所有属性,按列连接所有NumPy数组,连接顺序与construct_list_of_attributes()定义的顺序一致
        
        elements[:] = list(map(tuple, attributes)) 填充结构化数组,变成每行数据为元组的列表
        
        el = PlyElement.describe(elements, 'vertex') 创建PLY元素
        
        PlyData([el]).write(path)写入PLY文件



 def reset_opacity(self):
        opacities_new = self.inverse_opacity_activation(torch.min(self.get_opacity, torch.ones_like(self.get_opacity)*0.01))将当前不透明度值与0.01进行比较，取最小值，再将激活后的不透明度值转换回优化器使用的原始参数空间
        
        optimizable_tensors = self.replace_tensor_to_optimizer(opacities_new, "opacity")调用自定义方法替换优化器中的参数
        
        self._opacity = optimizable_tensors["opacity"]更新模型内部状态

def load_ply(self, path, use_train_test_exp = False):与save相反
        plydata = PlyData.read(path)使用plyfile库加载PLY文件数据
        
        if use_train_test_exp:构建曝光文件路径：假设在PLY文件的上两级目录
            exposure_file = os.path.join(os.path.dirname(path), os.pardir, os.pardir, "exposure.json")
            if os.path.exists(exposure_file):
                with open(exposure_file, "r") as f:
                    exposures = json.load(f)
                self.pretrained_exposures = {image_name: torch.FloatTensor(exposures[image_name]).requires_grad_(False).cuda() for image_name in exposures}
                print(f"Pretrained exposures loaded.")
            else:
                print(f"No exposure to be loaded at {exposure_file}")
                self.pretrained_exposures = None
          检查文件是否存在，如果存在：读取JSON格式的曝光数据，转换为PyTorch张量并移动到GPU，禁用梯度计算（requires_grad_(False)），按图像名称存储到self.pretrained_exposures
          如果不存在，设置self.pretrained_exposures = None



        xyz = np.stack((np.asarray(plydata.elements[0]["x"]),
                        np.asarray(plydata.elements[0]["y"]),
                        np.asarray(plydata.elements[0]["z"])),  axis=1)
        从PLY文件的第一个元素中提取x, y, z坐标，堆叠成形状为(N, 3)的数组
        
        opacities = np.asarray(plydata.elements[0]["opacity"])[..., np.newaxis]提取opacity属性，增加一个新维度使其变为(N, 1)

        features_dc = np.zeros((xyz.shape[0], 3, 1))
        features_dc[:, 0, 0] = np.asarray(plydata.elements[0]["f_dc_0"])
        features_dc[:, 1, 0] = np.asarray(plydata.elements[0]["f_dc_1"])
        features_dc[:, 2, 0] = np.asarray(plydata.elements[0]["f_dc_2"])
        创建形状为(N, 3, 1)的数组

        extra_f_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("f_rest_")]
        extra_f_names = sorted(extra_f_names, key = lambda x: int(x.split('_')[-1]))
        查找所有以"f_rest_"开头的属性名，按后缀数字排序（确保正确顺序）


        assert len(extra_f_names)==3*(self.max_sh_degree + 1) ** 2 - 3 检查高频分量数量是否符合预期，公式是3个通道 × (球谐系数总数 - DC分量)
        
        features_extra = np.zeros((xyz.shape[0], len(extra_f_names)))
        for idx, attr_name in enumerate(extra_f_names):
            features_extra[:, idx] = np.asarray(plydata.elements[0][attr_name])
        加载球谐高频分量，创建空数组存储高频分量，按顺序填充每个属性值
        
        # Reshape (P,F*SH_coeffs) to (P, F, SH_coeffs except DC)
        features_extra = features_extra.reshape((features_extra.shape[0], 3, (self.max_sh_degree + 1) ** 2 - 1))
        从(N, 45)重塑为(N, 3, 15)

        scale_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("scale_")]
        scale_names = sorted(scale_names, key = lambda x: int(x.split('_')[-1]))
        scales = np.zeros((xyz.shape[0], len(scale_names)))
        for idx, attr_name in enumerate(scale_names):
            scales[:, idx] = np.asarray(plydata.elements[0][attr_name])
            识别所有"scale_"属性并按数字排序，创建并填充缩放参数数组(N, 3)



        rot_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("rot")]
        rot_names = sorted(rot_names, key = lambda x: int(x.split('_')[-1]))
        rots = np.zeros((xyz.shape[0], len(rot_names)))
        for idx, attr_name in enumerate(rot_names):
            rots[:, idx] = np.asarray(plydata.elements[0][attr_name])
        与缩放类似
        
        self._xyz = nn.Parameter(torch.tensor(xyz, dtype=torch.float, device="cuda").requires_grad_(True))初始化位置参数，转换为PyTorch张量
        
        self._features_dc = nn.Parameter(torch.tensor(features_dc, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))转换为张量，从(N, 3, 1)到(N, 1, 3)
        
        self._features_rest = nn.Parameter(torch.tensor(features_extra, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))从(N, 3, 15)到(N, 15, 3)
        
        self._opacity = nn.Parameter(torch.tensor(opacities, dtype=torch.float, device="cuda").requires_grad_(True))
        
        self._scaling = nn.Parameter(torch.tensor(scales, dtype=torch.float, device="cuda").requires_grad_(True))
        
        self._rotation = nn.Parameter(torch.tensor(rots, dtype=torch.float, device="cuda").requires_grad_(True))

        self.active_sh_degree = self.max_sh_degree设置激活的球谐阶数，使用最大阶数


def replace_tensor_to_optimizer(self, tensor, name):

        optimizable_tensors = {}
        
        for group in self.optimizer.param_groups:
            if group["name"] == name:找到名称匹配的目标参数组
                stored_state = self.optimizer.state.get(group['params'][0], None)获取当前参数的优化器状态
                stored_state["exp_avg"] = torch.zeros_like(tensor)重置优化器状态
                stored_state["exp_avg_sq"] = torch.zeros_like(tensor)重置优化器状态

            遍历优化器的所有参数组，每个参数组包含一组共享相同超参数的参数


                del self.optimizer.state[group['params'][0]]删除旧参数的优化器状态
                
                group["params"][0] = nn.Parameter(tensor.requires_grad_(True))替换参数，启用梯度计算将参数组的第一个参数替换为新的张量，
                
                self.optimizer.state[group['params'][0]] = stored_state 将重置后的优化器状态关联到新参数

                optimizable_tensors[group["name"]] = group["params"][0]存储更新后的参数，以参数组名称为键，添加到返回字典中
                
        return optimizable_tensors





def _prune_optimizer(self, mask):

        optimizable_tensors = {}
        
        for group in self.optimizer.param_groups:
        
            stored_state = self.optimizer.state.get(group['params'][0], None)获取当前参数的优化器状态，如果不存在则返回None
            
            if stored_state is not None:如果该参数有优化器状态
            
                stored_state["exp_avg"] = stored_state["exp_avg"][mask]对一阶矩估计(动量)应用掩码
                
                stored_state["exp_avg_sq"] = stored_state["exp_avg_sq"][mask]对二阶矩估计(方差)应用掩码

                del self.optimizer.state[group['params'][0]]删除旧参数的优化器状态条目
                
                group["params"][0] = nn.Parameter((group["params"][0][mask].requires_grad_(True)))对当前参数应用掩码然后确保梯度计算，替换参数组中的原参数
                
                self.optimizer.state[group['params'][0]] = stored_state将修剪后的状态关联到新参数

                optimizable_tensors[group["name"]] = group["params"][0]存储修剪后的参数到返回字典
            else:处理没有优化器状态的情况
                group["params"][0] = nn.Parameter(group["params"][0][mask].requires_grad_(True))应用掩码修剪参数，不需要处理优化器状态
                optimizable_tensors[group["name"]] = group["params"][0]
        return optimizable_tensors


## 第四次记录
def prune_points(self, mask):
        valid_points_mask = ~mask 创建了一个新的布尔掩码，如果 mask 在需要剪枝的点处为 True，那么 ~mask 将在需要保留的点处为True

        optimizable_tensors = self._prune_optimizer(valid_points_mask)用了上面的代码，剪枝优化器，

        self._xyz = optimizable_tensors["xyz"]
        self._features_dc = optimizable_tensors["f_dc"]
        self._features_rest = optimizable_tensors["f_rest"]
        self._opacity = optimizable_tensors["opacity"]
        self._scaling = optimizable_tensors["scaling"]
        self._rotation = optimizable_tensors["rotation"]
        获取从上一个函数返回的字典的各个属性

        self.xyz_gradient_accum = self.xyz_gradient_accum[valid_points_mask]这一行剪枝了 xyz参数的累积梯度，因为当点被剪枝时，它们相关的累积梯度就不再需要了，剪枝这些梯度累积张量有助于减少内存消耗，并确保未来的优化步骤只考虑剩余活动点的梯度

        self.denom = self.denom[valid_points_mask]这一行剪枝了 denom（自适应的分母值）属性，优化器中任何按点划分的内部状态变量必须被剪枝，以匹配减少后的活动点集

        self.max_radii2D = self.max_radii2D[valid_points_mask]这一行剪枝了 max_radii2D 属性

        self.tmp_radii = self.tmp_radii[valid_points_mask]这一行剪枝了 tmp_radii 属性，tmp_radii定义在下面





def cat_tensors_to_optimizer(self, tensors_dict):
        optimizable_tensors = {}返回值，空字典

        for group in self.optimizer.param_groups:遍历优化器 self.optimizer 中的每一个参数组

            assert len(group["params"]) == 1 检查当前 group 中的 params 列表是否只包含一个参数，这确保了每个参数组只管理一个张量，这对于后续的代码逻辑（例如 group["params"][0]）是必要的，因为它假设每个组只有一个可优化张量需要处理和扩展。

            extension_tensor = tensors_dict[group["name"]]使用这个 name 作为键，从传入的 tensors_dict 中取出相应的新张量。

            stored_state = self.optimizer.state.get(group['params'][0], None)获取当前参数在优化器内部存储的状态，没有就返回none
            PyTorch 优化器通常会维护一个 state 字典，用于存储每个参数的优化器状态信息。对于 Adam 优化器，它会存储梯度的一阶矩估计（exp_avg）和二阶矩估计（exp_avg_sq）

            if stored_state is not None:当当前参数已经存在于优化器中，并且有其对应的优化器状态

                stored_state["exp_avg"] = torch.cat((stored_state["exp_avg"], torch.zeros_like(extension_tensor)), dim=0)
                exp_avg是的指数移动平均的一阶矩，创建一个与 extension_tensor 形状和数据类型相同，但所有元素都为零的新张量与原先的exp_avg沿指定维度（这里是 dim=0，即行方向）连接（拼接）两个张量。

                stored_state["exp_avg_sq"] = torch.cat((stored_state["exp_avg_sq"], torch.zeros_like(extension_tensor)), dim=0)
                exp_avg_sq 是平方梯度的指数移动平均（二阶矩），此时与上面类似
 
                del self.optimizer.state[group['params'][0]]由于我们即将创建一个新的参数张量，所以从优化器的 state 字典中删除旧的参数张量及其对应的状态，避免内存泄漏和状态不一致

                group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                self.optimizer.state[group['params'][0]] = stored_state
                将当前参数组中已有的参数张量 (group["params"][0]) 与新的 extension_tensor 沿 dim=0 拼接起来。这实际上就是将新的高斯点的数据添加到现有高斯点数据之后，而新的合并张量在反向传播时将计算梯度，使其可被优化，又因为PyTorch 优化器期望其管理的参数是 nn.Parameter 类型的对象，所以即使 torch.cat 返回一个张量，我们也需要将其包装成 nn.Parameter

                optimizable_tensors[group["name"]] = group["params"][0]将更新后的 stored_state重新关联到新的参数张量上，确保优化器能够继续对所有参数（包括新添加的）进行正确的更新

            else:如果 stored_state 是 None
                group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                行为与上面 if 块中的相同。它直接将现有参数和新参数拼接起来，并将其包装成 nn.Parameter。

                optimizable_tensors[group["name"]] = group["params"][0]将新合并的参数存储到 optimizable_tensors 字典中。
                直接拼接参数张量并设置为可求导即可。

        return optimizable_tensors



def densification_postfix(self, new_xyz, new_features_dc, new_features_rest, new_opacities, new_scaling, new_rotation, new_tmp_radii):用于稠密化的后期处理，在生成了新的高斯点之后，将这些新点的数据整合到模型的核心参数中，并为它们初始化相关的优化器状态和辅助数据
        d = {"xyz": new_xyz,
        "f_dc": new_features_dc,
        "f_rest": new_features_rest,
        "opacity": new_opacities,
        "scaling" : new_scaling,
        "rotation" : new_rotation}
        创建一个字典 d，将传入的新高斯点数据组织起来，将所有需要通过优化器扩展的新参数捆绑在一起，以便于传递给 self.cat_tensors_to_optimizer

        optimizable_tensors = self.cat_tensors_to_optimizer(d)
        self._xyz = optimizable_tensors["xyz"]
        self._features_dc = optimizable_tensors["f_dc"]
        self._features_rest = optimizable_tensors["f_rest"]
        self._opacity = optimizable_tensors["opacity"]
        self._scaling = optimizable_tensors["scaling"]
        self._rotation = optimizable_tensors["rotation"]
        用 cat_tensors_to_optimizer 返回的、已更新的参数张量来更新 self 实例对应的内部属性。

        self.tmp_radii = torch.cat((self.tmp_radii, new_tmp_radii))将 new_tmp_radii（新高斯点的临时半径数据）与现有 self.tmp_radii 张量进行拼接，确保所有与高斯点数量相关的辅助数据都同步更新
        
        重新初始化一些与优化和渲染相关的辅助张量
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")并将其放置在 CUDA 设备上，重新初始化高斯点位置的梯度累积
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")初始分母项
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")初始最大半径



## 第五次记录
def densify_and_split(self, grads, grad_threshold, scene_extent, N=2):根据渲染过程中计算出的梯度信息，对场景中的高斯点进行稠密化处理，分裂成两个

        n_init_points = self.get_xyz.shape[0] 获取当前场景中高斯点的总数量

        # Extract points that satisfy the gradient condition
        padded_grad = torch.zeros((n_init_points), device="cuda")创建一个与当前高斯点总数相同大小的零张量，并放置在 CUDA 设备上，确保 grads，能够与 n_init_points 对齐

        padded_grad[:grads.shape[0]] = grads.squeeze()将传入的 grads 填充到 padded_grad 中，统一梯度张量的长度，以便后续的筛选操作

        selected_pts_mask = torch.where(padded_grad >= grad_threshold, True, False)创建一个布尔掩码。所有梯度大于等于 grad_threshold 的高斯点对应的位置在 selected_pts_mask 中为 True，否则为 False。因为高梯度区域通常意味着渲染误差较大，需要更多的高斯点来更好地表示。

        selected_pts_mask = torch.logical_and(selected_pts_mask,
                                              torch.max(self.get_scaling, dim=1).values > self.percent_dense*scene_extent)
        先获取获取每个高斯点在三个尺度轴（x, y, z）上的最大尺度值，用self.percent_dense * scene_extent这个与场景大小相关的尺度阈值，来判断高斯点是否足够大，梯度条件和尺度条件结合，只有同时满足梯度大 (说明它很重要) 并且尺度大，才会被最终选中，防止对那些已经很小的高斯点进行分裂，因为它们可能已经提供了足够的细节。同时，确保只在需要更多细节的区域（大梯度）分裂。

        stds = self.get_scaling[selected_pts_mask].repeat(N,1)获取被选中高斯点的尺度，并将其在第一个维度上重复 N 次。这些尺度将作为生成新高斯点位置时的标准差

        means =torch.zeros((stds.size(0), 3),device="cuda")创建一个与 stds 相同大小的零均值张量。

        samples = torch.normal(mean=means, std=stds)从一个正态分布中采样新的位置偏移量。因为以原始高斯点的尺度作为标准差，从零均值的正态分布中采样，可以确保新的子高斯点在空间上围绕原始高斯点分布，并且其分布范围与原始高斯点的尺寸相关，使生成每个新高斯点相对于其父高斯点中心的随机偏移量

        rots = build_rotation(self._rotation[selected_pts_mask]).repeat(N,1,1)获取被选中高斯点的旋转信息，并重复 N 次。

        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[selected_pts_mask].repeat(N, 1)计算新高斯点的三维坐标，先将将 samples 转换为列向量，以便与旋转矩阵进行矩阵乘法，然后再将采样到的偏移量 samples 乘以旋转矩阵 rots，因为这样能确保随机偏移是在高斯点的局部坐标系中进行的，然后再将其转换回世界坐标系。如果直接在世界坐标系中添加偏移，那么当高斯点有旋转时，其子高斯点可能不会沿着原始高斯点的主轴方向分布。接着.squeeze(-1)将结果变回三维坐标，+ self.get_xyz[selected_pts_mask].repeat(N, 1):最后将旋转后的偏移量加到原始高斯点的坐标上，得到新高斯点的最终坐标。


        new_scaling = self.scaling_inverse_activation(self.get_scaling[selected_pts_mask].repeat(N,1) / (0.8*N))计算新高斯点的尺度，将原始高斯点的尺度除以 0.8*N，意味着每个新分裂出来的子高斯点的尺度都会比其父高斯点小，再将缩放后的值通过逆激活函数转换，将这些值转换回原始的非激活空间，方便存储和进一步处理。
        下面都类似
        new_rotation = self._rotation[selected_pts_mask].repeat(N,1)
        new_features_dc = self._features_dc[selected_pts_mask].repeat(N,1,1)
        new_features_rest = self._features_rest[selected_pts_mask].repeat(N,1,1)
        new_opacity = self._opacity[selected_pts_mask].repeat(N,1)
        new_tmp_radii = self.tmp_radii[selected_pts_mask].repeat(N)

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacity, new_scaling, new_rotation, new_tmp_radii)将新生成的高斯点添加到主高斯点集合中

        prune_filter = torch.cat((selected_pts_mask, torch.zeros(N * selected_pts_mask.sum(), device="cuda", dtype=bool)))创建一个用于修剪高斯点的布尔掩码，被选中用于分裂的原始高斯点应该被修剪掉，而新生成的高斯点则保留。

        self.prune_points(prune_filter)调用另一个辅助函数，根据 prune_filter 移除不再需要的高斯点。

  def densify_and_clone(self, grads, grad_threshold, scene_extent):通过克隆现有高斯点来增加场景的表示密度。它会选择那些在渲染过程中对误差贡献较大（梯度大）且尺寸较小的高斯点进行克隆，从而在这些区域增加更多的表示能力。

        # Extract points that satisfy the gradient condition
        selected_pts_mask = torch.where(torch.norm(grads, dim=-1) >= grad_threshold, True, False)
        torch.norm(grads, dim=-1)是计算每个高斯点梯度的 L2 范数（欧几里得范数），根据梯度的范数与 grad_threshold 的比较，创建一个布尔掩码。只有梯度范数大于等于 grad_threshold 的高斯点才会被初步选中。识别那些对渲染结果产生较大影响（即有较高误差）的高斯点，因为这些区域通常需要更密集的表示。

        selected_pts_mask = torch.logical_and(selected_pts_mask,
                                              torch.max(self.get_scaling, dim=1).values <= self.percent_dense*scene_extent)判断高斯点是否小，将梯度条件和尺度条件结合起来。只有同时满足梯度大 (说明它很重要) 并且尺度小(说明它可能不足以覆盖所有细节) 的高斯点才会被最终选中，因为我们希望克隆那些已经比较小但仍然有高梯度的点
        
        下面都是直接克隆高斯点属性，创建与被选中的高斯点完全相同的新高斯点
        new_xyz = self._xyz[selected_pts_mask]
        new_features_dc = self._features_dc[selected_pts_mask]
        new_features_rest = self._features_rest[selected_pts_mask]
        new_opacities = self._opacity[selected_pts_mask]
        new_scaling = self._scaling[selected_pts_mask]
        new_rotation = self._rotation[selected_pts_mask]
        new_tmp_radii = self.tmp_radii[selected_pts_mask]

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacities, new_scaling, new_rotation, new_tmp_radii)将新创建（克隆）的高斯点有效地整合到场景的高斯点数据结构中



def densify_and_prune(self, max_grad, min_opacity, extent, max_screen_size, radii):自适应控制高斯点数量和质量的核心函数

        grads = self.xyz_gradient_accum / self.denom将累积梯度除以其被渲染的次数，得到的是平均梯度。平均梯度比原始梯度更能稳定地反映一个高斯点对渲染误差的持续贡献， 获取每个高斯点在最近一段时间内的平均位置梯度。这个梯度是判断哪些区域需要稠密化的主要依据。

        grads[grads.isnan()] = 0.0将 grads 中所有 NaN（Not a Number）值替换为 0.0，NaN 值通常表示在某些情况下，某个高斯点可能没有参与任何渲染，导致其 denom 为零或梯度计算出现问题。将 NaN 设为 0 可以避免后续计算中的错误，并且意味着这些点对渲染没有贡献，无需进行稠密化。

        self.tmp_radii = radii  将传入的 radii（当前帧中高斯点的 2D 投影半径）存储为实例变量 self.tmp_radii，这使得 densify_and_clone 和 densify_and_split 函数能够访问到高斯点在屏幕上的大小信息。虽然这两个函数在它们的参数列表中没有直接接收 radii，但它们可能在内部通过 self.tmp_radii 或 self.max_radii2D，因为稠密化策略通常需要结合高斯点的空间大小和其在屏幕上的投影大小来做出决策。

        self.densify_and_clone(grads, max_grad, extent)克隆那些梯度大且尺寸相对较小的高斯点。这增加了在特定区域的高斯点数量，而不改变它们的大小。

        self.densify_and_split(grads, max_grad, extent)分裂那些梯度大且尺寸较大的高斯点。这会将一个大高斯点分解为多个更小、更精细的高斯点。

        prune_mask = (self.get_opacity < min_opacity).squeeze()创建一个初步的剪枝掩码，标记那些不透明度低于 min_opacity 的高斯点。移除那些几乎透明的高斯点
        if max_screen_size:如果 max_screen_size 参数被设置，则执行额外的剪枝。

            big_points_vs = self.max_radii2D > max_screen_size 标记那些在屏幕上投影的 2D 半径 (self.max_radii2D) 超过 max_screen_size 的高斯点，剪枝那些在屏幕上看起来非常大的高斯点

            big_points_ws = self.get_scaling.max(dim=1).values > 0.1 * extent标记那些在世界空间中尺度过大的高斯点。这种剪枝与 densify_and_split 结合，形成了一种“大点修剪，小点分裂”的机制，因为过大的高斯点可能不利于精细化表示

            prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws)将所有剪枝条件（低不透明度、屏幕尺寸过大、世界空间尺寸过大）通过逻辑或 (logical_or) 组合起来。

        self.prune_points(prune_mask)调用 prune_points 辅助函数，根据最终的 prune_mask 移除被标记的高斯点，实际执行高斯点的删除操作，减少模型中的冗余和低效点。
        tmp_radii = self.tmp_radii 将 self.tmp_radii 的值保存到一个局部变量。

        self.tmp_radii = None 将 self.tmp_radii 清空，因为self.tmp_radii 是一个临时变量，仅在 densify_and_prune 函数内部使用，可以避免潜在的副作用或混淆，确保在下一次调用时总是使用最新的 radii 信息。

        torch.cuda.empty_cache()强制 CUDA 分配器将所有当前未使用的缓存内存释放回 GPU，使其可供其他进程或你自己的 PyTorch 操作使用


def add_densification_stats(self, viewspace_point_tensor, update_filter):用于累积高斯点的位置梯度和被渲染的次数
        self.xyz_gradient_accum[update_filter] += torch.norm(viewspace_point_tensor.grad[update_filter,:2], dim=-1, keepdim=True)先使用首先使用 update_filter 来选择那些需要更新的高斯点的梯度，然后选择梯度的前两个维度，因为渲染图像主要受到高斯点在屏幕上投影的 X 和 Y 坐标影响。因此，我们关注这两个维度的梯度。，计算渲染图像相对于高斯点在视图空间投影位置的梯度，再用torch.norm计算所选梯度向量的 L2 范数，梯度的范数代表了高斯点在视图空间中对渲染误差的综合影响强度。范数越大，说明该高斯点在视图空间中的位置稍微移动就会对渲染结果产生更大的变化，暗示该区域可能需要更精细的表示，最后再将计算出的梯度范数累加到 self.xyz_gradient_accum 这个成员变量中，持续跟踪每个高斯点在多个训练步骤中对渲染误差的平均贡献。通过累积，可以得到更稳定和鲁棒的梯度估计，避免单次迭代中梯度噪声的影响。

        self.denom[update_filter] += 1 对于 update_filter 中为 True 的高斯点（即那些在当前帧中参与了渲染的高斯点），将其对应的计数器加 1。

