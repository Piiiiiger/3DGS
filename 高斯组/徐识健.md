# 第一周
## 第一次学习记录
# 1.初始化与参数定义
## 1️⃣代码
```
class GaussianModel:
    # ... (setup_functions 方法) ...

    def __init__(self, sh_degree, optimizer_type="default"):
        self.active_sh_degree = 0
        self.optimizer_type = optimizer_type
        self.max_sh_degree = sh_degree
        self._xyz = torch.empty(0)
        self._features_dc = torch.empty(0)
        self._features_rest = torch.empty(0)
        self._scaling = torch.empty(0)
        self._rotation = torch.empty(0)
        self._opacity = torch.empty(0)
        self.max_radii2D = torch.empty(0)
        self.xyz_gradient_accum = torch.empty(0)
        self.denom = torch.empty(0)
        self.optimizer = None
        self.percent_dense = 0
        self.spatial_lr_scale = 0
        self.setup_functions()
```
### ==self._features_dc = torch.empty(0)==
<font color="#2DC26B">定义：</font>存储所有3D高斯点球谐函数的直流 (DC) 分量：代表每个高斯点的基础颜色，不受视角变化影响的部分。
<font color="#2DC26B">形状：</font>(N, 1, C)：有时会被转置（N,C,1）
### ==self._features_rest = torch.empty(0)==
<font color="#2DC26B">定义：</font>用于存储所有3D高斯点球谐函数的交流 (AC) 分量，即除了0阶之外的高阶系数-捕获每个高斯点颜色随视角变化的复杂外观
<font color="#2DC26B">形状</font>：(N, S, C)
<u>球谐函数：</u>
<font color="#2DC26B">SH阶数：</font>
**0阶 (Degree 0)**: 只有一个基函数，它在球面上是常数。对应于漫反射颜色或平均颜色，不随视角变化。这就是 `_features_dc` 存储的内容。
**1阶 (Degree 1)**: 有三个基函数，可以表示一些简单的方向性变化，比如一个方向更亮，反方向更暗。
**更高阶**: 可以表示更复杂的高光、各向异性反射等。`_features_rest` 存储的就是这些1阶及以上阶数的系数。
### ==self._scaling = torch.empty(0)==
![[Pasted image 20250513202151.png]]
<font color="#2DC26B">定义</font>：每行代表一个高斯点在局部坐标系下三个主轴方向上的缩放值    W：放缩矩阵
<font color="#2DC26B">形状</font>：（N，3）
与旋转参数一起构建协方差矩阵

### ==self._otation = torch.empty(0)==

<font color="#2DC26B">定义</font>： 用于存储每个3D高斯点的旋转信息，通常以四元数 (quaternion) 的形式表示。
<font color="#2DC26B">形状</font>：（N，4）
<font color="#2DC26B">作用：</font>定义了高斯椭球在3D空间中的朝向。这些四元数会经过归一化处理以确保它们是有效的单位四元数。
<font color="#f79646">为何用四元数</font>：
<font color="#4bacc6">欧拉角</font> (Euler Angles): 例如，绕X、Y、Z轴分别旋转一定的角度。直观，但存在万向锁 (Gimbal Lock) 问题，并且插值不平滑。
欧拉角通过指定物体依次绕三个轴旋转一定的角度来定义最终的朝向。我们选择一个常见的顺序：ZYX (偏航 Yaw, 俯仰 Pitch, 翻滚 Roll)。
- **Yaw (偏航)**: 绕物体的初始Y轴旋转。
- **Pitch (俯仰)**: 绕物体**新的**X轴（经过Yaw旋转后的X轴）旋转。
- **Roll (翻滚)**: 绕物体**更新的**Z轴（经过Yaw和Pitch旋转后的Z轴）旋转。


**旋转矩阵 (Rotation Matrices)**: 3x3的正交矩阵。无万向锁问题，但有9个参数，其中只有3个自由度，存在冗余，且直接优化9个参数并保持其正交性也比较复杂。

-**轴-角表示法 (Axis-Angle)**: 用一个旋转轴（单位向量）和一个旋转角度来表示。比较紧凑，但插值和组合旋转不如四元数方便。

**四元数 (Quaternions)**: 一种扩展复数的数学概念，由一个实部和三个虚部组成，通常表示为 q=w+xi+yj+zk 或向量形式 [w,x,y,z]。

### ==为何要分成两个参数：==
直接优化协方差矩阵的元素很困难，因为需要保证其物理上的有效性（即半正定性）。梯度下降等优化算法很难直接施加这样的约束，很容易产生无效的协方差矩阵。


## 第二次学习记录

### self.denom = torch.empty(0)
- **含义**: `denom` 是 "denominator"（分母）的缩写。它是一个计数器，与 `xyz_gradient_accum` (梯度累加器) 配套使用。
    
- **作用**: 在训练过程中，每当一个高斯球对最终图像的某个像素有贡献时，它的位置梯度就会被累加到 `xyz_gradient_accum` 中，同时它的 `denom` 计数器就会加 1。
- 
    
- **目的**: 为了计算**平均梯度**。论文中提到，致密化（densification）的依据是“视空间位置梯度的平均幅度” (average magnitude of view-space position gradients) 。如果只看梯度的总和，那么一个经常被看到的、位置合适的高斯球可能会因为累加次数多而产生很高的总梯度，这会带来误判。因此，用总梯度
    
    `xyz_gradient_accum` 除以被看到的次数 `denom`，得到平均梯度 `grads = self.xyz_gradient_accum / self.denom`，才能更准确地判断这个高斯球所在区域是否真的需要被“致密化”。
### self.optimizer = None
- **含义**: 这是PyTorch中的优化器对象。
    
- **作用**: 优化器的任务是在每次反向传播计算出梯度后，根据自身的优化算法（例如Adam）来更新模型的所有可学习参数（如 `_xyz`, `_scaling` 等）。
    
- **为什么初始为`None`**: 在`__init__`阶段，模型框架刚刚搭建好，但还没有从点云加载任何实际的高斯球数据，所有参数张量都是空的。优化器需要绑定到具体的参数上才能工作，因此不能在此时创建。它会在后续的`training_setup`函数中，当所有参数都从点云初始化完毕后，才被正式创建和赋值。

### self.percent_dense = 0
- **含义**: 这个参数是用来区分“小”高斯球和“大”高斯球的一个阈值因子。它在`training_setup`函数中会被赋予一个来自训练参数的实际值。
    
- **作用**: 它是实现论文中两种不同致密化策略的关键。论文提到，对于“欠重建”区域的小高斯球，采用**克隆（Clone）** 策略；对于“过重建”区域的大高斯球，采用**分裂（Split）** 策略 。z
- **==作用二==**：限制大致限制高斯球的大小
    
- **如何工作**:
    
    - 在`densify_and_clone`中，只有尺寸**小于** `percent_dense * scene_extent` 的高斯球才会被考虑克隆。
        
    - 在`densify_and_split`中，只有尺寸**大于** `percent_dense * scene_extent` 的高斯球才会被考虑分裂。 `scene_extent`是整个场景的大致范围，所以这个参数实际上是根据高斯球尺寸相对于整个场景的比例来做判断的

### self.spatial_lr_scale = 0
- **含义**: “空间学习率缩放因子” (Spatial Learning Rate Scale)。
    
- **作用**: 这是一个专门用来调整高斯球**位置（xyz）学习率**的缩放系数。
    
- **目的**: 允许独立控制高斯球“移动快慢”（位置变化）和其他属性“变化快慢”（如颜色、形状、透明度变化）。在`training_setup`中设置优化器时，位置参数`_xyz`的学习率会乘以这个缩放因子：`training_args.position_lr_init * self.spatial_lr_scale`。这非常有用，因为在一些非常大的场景中，如果位置学习率过高，高斯球在训练初期可能会移动得过快，导致不稳定。通过这个缩放因子，可以根据场景的大小来适当调整位置学习率，以保证训练的稳定性和收敛效果 。


## 第三次学习记录
今天主要侧重于进行透明度筛选
设置了一个筛选掉低透明度的方法，但是总体感觉效果一般

#### train.py

- 过滤掉颜色接近黑色的高斯点   错误
```
print(gaussians.colors)
valid_points = torch.any(gaussians.colors > 0.1, dim=1)  # 颜色阈值为 0.1，可根据需要调整
gaussians.positions = gaussians.positions[valid_points]
gaussians.colors = gaussians.colors[valid_points]
gaussians.max_radii2D = gaussians.max_radii2D[valid_points]
```
#### __init__.py
- self.densify_until_iter = 1000
- self.sh_degree = 0

## 第四次学习记录
# 2.参数的激活与获取
## 2.1目的
核心问题：为什么需要“激活”？

这个设计的出发点是为了解决一个矛盾：

- **优化器的世界**：像Adam这样的优化器，在更新参数时没有任何限制，它可以把一个数值从0.1更新到-100。它在无约束的数学空间中工作效率最高。
    
- **物理世界**：场景中的属性是有严格约束的。例如，一个物体的尺寸（缩放）必须是正数；不透明度必须在0到1之间；旋转必须是有效的刚体变换，不能包含拉伸或挤压。
    

如果直接优化有物理意义的参数（比如尺寸），优化器一次更新就可能把它变成一个无效的负数，导致整个计算崩溃。

**解决方案**：代码采用了一种“双重世界”的架构。它在内部存储一组无约束的原始参数（如`_scaling`, `_opacity`），然后定义一套“规则”，将这些原始参数“翻译”或“激活”成符合物理约束的属性。
## 2.2`setup_functions(self)`: 定义“翻译规则”
### 2.2.1 代码
```python
class GaussianModel:

    def setup_functions(self):
        def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):
            L = build_scaling_rotation(scaling_modifier * scaling, rotation)
            actual_covariance = L @ L.transpose(1, 2)
            symm = strip_symmetric(actual_covariance)
            return symm
        
        self.scaling_activation = torch.exp
        self.scaling_inverse_activation = torch.log

        self.covariance_activation = build_covariance_from_scaling_rotation

        self.opacity_activation = torch.sigmoid
        self.inverse_opacity_activation = inverse_sigmoid

        self.rotation_activation = torch.nn.functional.normalize
```

### 2.2.2 build_covariance_from_scaling_rotation
#### (1)作用
实现
$$\Sigma = RSS^T R^T$$
#### (2)build_scaling_rotation
参数：scaling_modifier+scaling+rotation
作用：scaling_modifier可以临时调整高斯点大小
scaling:三维向量
rotaion：四元数
#### (3)actual_covariance = L @ L.transpose(1, 2)
解决$$L@L^T = (R@S)@(R@S)^T = R@S@S^T@R^T$$transpose(1, 2)交换1列和2列


#### (4)**`symm = strip_symmetric(actual_covariance)`**
节约效率，将3X3矩阵的保存的对称矩阵转化为6元素
2这样做可以减少需要传输到GPU渲染器的数据量，提高渲染效率。

## 2.3 capture和restore
#### 2.3.1`capture(self)`: 制作一个“完整快照” 📸
这个方法的作用是**捕获**当前模型在训练过程中的**所有关键状态**，并将它们打包成一个元组（tuple）返回。

它不仅仅保存了高斯球本身的几何与颜色参数，更重要的是，它还保存了与**训练过程本身相关的状态**。

具体来说，它打包了以下信息:

- **模型核心参数**: `_xyz`, `_features_dc`, `_features_rest`, `_scaling`, `_rotation`, `_opacity`。
    
- **训练辅助状态**:
    
    - `active_sh_degree`: 当前使用的球谐函数阶数。
        
    - `max_radii2D`: 用于剪枝判断的2D半径。
        
    - `xyz_gradient_accum`, `denom`: 用于自适应密度控制的梯度累加器和分母。
        
    - `spatial_lr_scale`: 空间学习率缩放因子。
        
- **优化器状态 (最关键)**: `self.optimizer.state_dict()`。这会返回一个包含优化器内部状态的字典，比如Adam优化器中每个参数的动量（momentum）和二阶矩估计。
    

**目的**: 创建一个完整的“存档点”。只保存模型参数 `_xyz` 等是不够的，因为要无缝地继续训练，必须恢复优化器之前的状态。否则，优化器会丢失动量，训练的收敛速度和路径都会受影响。

---

### `restore(self)`: 从“快照”中恢复 💾

这个方法的作用是接收一个由 `capture` 方法创建的“快照”数据，并将模型的**所有状态恢复到存档时的那一刻**。

它的执行流程非常严谨：

1. **解包数据**: 它首先将传入的元组 `model_args` 解包，把保存的参数和状态值赋给当前模型的对应属性。
    
2. **重建优化器**: 它调用 `self.training_setup(training_args)`。这一步会根据当前的参数重新创建一个**全新的、没有内部状态**的优化器实例。
    
3. **恢复训练状态**: 将解包得到的 `xyz_gradient_accum` 和 `denom` 赋值给模型。
    
4. **加载优化器状态**: 最后，也是最关键的一步，它调用 `self.optimizer.load_state_dict(opt_dict)`。这个命令会将存档中的优化器状态（动量等）加载到第2步创建的那个**新优化器**中。
    

**目的**: 确保模型不仅参数和存档时一模一样，连优化器的“训练节奏”和“惯性”也完全恢复。这样，你中断训练再从这个存档点继续时，其效果就和从未中断过训练完全一样。

---

## 2.4装饰器
提供一个**统一、安全、只读的接口**，让外部代码（如渲染器）可以获取高斯球的**物理属性**，而不是直接接触内部存储的、未经处理的**原始参数**。

### 2.4.1 代码
```python
@property
def get_scaling(self):
	return self.scaling_activation(self._scaling)
@property
def get_rotation(self):
	return self.rotation_activation(self._rotation)
@property
def get_xyz(self):
	return self._xyz
@property
def get_features(self):
	features_dc = self._features_dc
	features_rest = self._features_rest
	return torch.cat((features_dc, features_rest), dim=1)
@property
def get_features_dc(self):
	return self._features_dc
@property
def get_features_rest(self):
	return self._features_rest
@property
def get_opacity(self):
	return self.opacity_activation(self._opacity)
@property
def get_exposure(self):
	return self._exposure
```
## 2.5 获取其他参数
### 2.5.1 get_exposure_from_name
```python
def get_exposure_from_name(self, image_name):

	if self.pretrained_exposures is None:
	
		return self._exposure[self.exposure_mapping[image_name]]
	
	else:
	
		return self.pretrained_exposures[image_name]
```
**作用**: 根据输入的**图像文件名**，获取该图像对应的**曝光补偿参数**。
这个函数内部有两种工作模式：
1. **当 `self.pretrained_exposures` 为 `None` 时 (正常训练模式)**:
    
    - 它会使用之前创建的 `self.exposure_mapping` 字典，将 `image_name` 转换成一个索引号。
        
    - 然后用这个索引号，从正在学习的 `_exposure` 参数张量中，取出专属于这张图像的那个 3x4 变换矩阵并返回。
        
2. **当 `self.pretrained_exposures` 不为 `None` 时 (使用预设值模式)**:
    
    - 这种情况发生在 `load_ply` 函数从外部 `exposure.json` 文件中成功加载了预先计算好的曝光值之后。
        
    - 函数会直接在 `self.pretrained_exposures` 这个字典里查找并返回对应 `image_name` 的曝光参数，而**不是**使用模型内部正在学习的 `_exposure`。
        

**总结**: 这个函数是一个智能的获取器，它能根据当前是需要**动态学习**曝光还是**使用固定预设值**，来提供正确的曝光补偿矩阵。

# 3.从点云初始化场景
## 3.1 参数介绍
- pcd : BasicPointCloud:    包括位置信息和颜色信息
- cam_infos : int 相机信息
- spatial_lr_scale : float ：根据pcd计算出的尺寸信息
## 3.2 初始化准备
```python
self.spatial_lr_scale = spatial_lr_scale
fused_point_cloud = torch.tensor(np.asarray(pcd.points)).float().cuda()
fused_color = RGB2SH(torch.tensor(np.asarray(pcd.colors)).float().cuda())
```
## 3.3 缩放和旋转的初始化
```python
dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)## 计算点云之间的距离并且防止距离过小或重叠，如果距离过小，那么就设置距离为指定值

scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3) ## 计算缩放参数，使用对数缩放距离,使用log 的原因是因为激活函数是exp，所以这里需要对距离进行对数缩放

rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")

rots[:, 0] = 1
```

### 3.3.1放缩举例
```
原始 dist2: tensor([25., 4., 16.]) 
原始 dist2 形状: torch.Size([3]) 
最终 scales: tensor(
[
[1.6094, 1.6094, 1.6094], 
[0.6931, 0.6931, 0.6931], 
[1.3863, 1.3863, 1.3863]]) 
最终 scales 形状: torch.Size([3, 3]) 
```

[n,3]分别对应x,y,z轴
### 3.3.2旋转举例
```
[[1.0, 0.0, 0.0, 0.0], # P0 对应的初始 _rotation 参数 
[1.0, 0.0, 0.0, 0.0], # P1 对应的初始 _rotation 参数 
[1.0, 0.0, 0.0, 0.0]] # P2 对应的初始 _rotation 参数
```
表示单位旋转

### 3.3.3注册可学习参数
```python
self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True))
self._features_dc = nn.Parameter(features[:,:,0:1].transpose(1, 2).contiguous().requires_grad_(True))
self._features_rest = nn.Parameter(features[:,:,1:].transpose(1, 2).contiguous().requires_grad_(True))
self._scaling = nn.Parameter(scales.requires_grad_(True))
self._rotation = nn.Parameter(rots.requires_grad_(True))
self._opacity = nn.Parameter(opacities.requires_grad_(True))
self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")
self.exposure_mapping = {cam_info.image_name: idx for idx, cam_info in enumerate(cam_infos)}
self.pretrained_exposures = None
exposure = torch.eye(3, 4, device="cuda")[None].repeat(len(cam_infos), 1, 1)
self._exposure = nn.Parameter(exposure.requires_grad_(True))
```

#### (1)nn.Parameter
- **作用**: `torch.nn.Parameter` 是一个特殊的类，它像一个“标签”，用来告诉PyTorch：“这个张量（Tensor）是我模型的一部分，它需要被学习和更新。请在训练时跟踪它的梯度。”
#### (2)contiguous()
- **经过 `.transpose()` 操作后的张量**：这本书的物理页码还是 1, 2, 3, ...，但你拿到了一张“阅读顺序卡”，上面写着“先读第1页，再读第50页，再读第2页...”。你依然能读完整本书，但需要不停地来回跳转，**效率很低**。这时，这本书在逻辑上是转置过的，但在内存中是**“不连续的”（Non-contiguous）**。
    
- **`.contiguous()` 函数**：它的作用就像一个图书管理员，他会根据你的“阅读顺序卡”，把书的页面**重新物理排序**，整理成一本全新的、页码按新顺序 1, 50, 2, ... 排列的书。这样你再读起来就又变得很快了。

#### (3)exposure_mapping
目的：
模型的曝光参数 `_exposure` 是一个 `(N, 3, 4)` 的大张量，其中 `N` 是相机的总数。要获取第一张照片的曝光参数，你需要访问 `_exposure[0]`；要获取第二张的，需要访问 `_exposure[1]`。

在训练时，程序知道当前处理的是哪张图片（比如`"003.jpg"`），但它不知道这张图片对应的是第几个曝光参数。

这个 `exposure_mapping` 字典就解决了这个问题。程序可以通过 `idx = self.exposure_mapping["003.jpg"]` 瞬间查到它的索引是 `2`，然后就能准确地从 `_exposure[2]` 中取出正确的曝光参数了。
`cam_info.image_name: idx`: 这定义了字典的“键值对”。

- **键 (key)**: `cam_info.image_name` (图像的文件名)
    
- **值 (value)**: `idx` (该图像在列表中的索引号)
最后形成
```
{
    "001.jpg": 0,
    "002.jpg": 1,
    "003.jpg": 2,
    # ...
}
