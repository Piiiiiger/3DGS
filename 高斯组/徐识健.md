# 第一周
## 第一次学习记录
# 1.初始化与参数定义
## 1️⃣代码
```
class GaussianModel:
    # ... (setup_functions 方法) ...

    def __init__(self, sh_degree, optimizer_type="default"):
        self.active_sh_degree = 0
        self.optimizer_type = optimizer_type
        self.max_sh_degree = sh_degree
        self._xyz = torch.empty(0)
        self._features_dc = torch.empty(0)
        self._features_rest = torch.empty(0)
        self._scaling = torch.empty(0)
        self._rotation = torch.empty(0)
        self._opacity = torch.empty(0)
        self.max_radii2D = torch.empty(0)
        self.xyz_gradient_accum = torch.empty(0)
        self.denom = torch.empty(0)
        self.optimizer = None
        self.percent_dense = 0
        self.spatial_lr_scale = 0
        self.setup_functions()
```
### ==self._features_dc = torch.empty(0)==
<font color="#2DC26B">定义：</font>存储所有3D高斯点球谐函数的直流 (DC) 分量：代表每个高斯点的基础颜色，不受视角变化影响的部分。
<font color="#2DC26B">形状：</font>(N, 1, C)：有时会被转置（N,C,1）
### ==self._features_rest = torch.empty(0)==
<font color="#2DC26B">定义：</font>用于存储所有3D高斯点球谐函数的交流 (AC) 分量，即除了0阶之外的高阶系数-捕获每个高斯点颜色随视角变化的复杂外观
<font color="#2DC26B">形状</font>：(N, S, C)
<u>球谐函数：</u>
<font color="#2DC26B">SH阶数：</font>
**0阶 (Degree 0)**: 只有一个基函数，它在球面上是常数。对应于漫反射颜色或平均颜色，不随视角变化。这就是 `_features_dc` 存储的内容。
**1阶 (Degree 1)**: 有三个基函数，可以表示一些简单的方向性变化，比如一个方向更亮，反方向更暗。
**更高阶**: 可以表示更复杂的高光、各向异性反射等。`_features_rest` 存储的就是这些1阶及以上阶数的系数。
### ==self._scaling = torch.empty(0)==
![[Pasted image 20250513202151.png]]
<font color="#2DC26B">定义</font>：每行代表一个高斯点在局部坐标系下三个主轴方向上的缩放值    W：放缩矩阵
<font color="#2DC26B">形状</font>：（N，3）
与旋转参数一起构建协方差矩阵

### ==self._otation = torch.empty(0)==

<font color="#2DC26B">定义</font>： 用于存储每个3D高斯点的旋转信息，通常以四元数 (quaternion) 的形式表示。
<font color="#2DC26B">形状</font>：（N，4）
<font color="#2DC26B">作用：</font>定义了高斯椭球在3D空间中的朝向。这些四元数会经过归一化处理以确保它们是有效的单位四元数。
<font color="#f79646">为何用四元数</font>：
<font color="#4bacc6">欧拉角</font> (Euler Angles): 例如，绕X、Y、Z轴分别旋转一定的角度。直观，但存在万向锁 (Gimbal Lock) 问题，并且插值不平滑。
欧拉角通过指定物体依次绕三个轴旋转一定的角度来定义最终的朝向。我们选择一个常见的顺序：ZYX (偏航 Yaw, 俯仰 Pitch, 翻滚 Roll)。
- **Yaw (偏航)**: 绕物体的初始Y轴旋转。
- **Pitch (俯仰)**: 绕物体**新的**X轴（经过Yaw旋转后的X轴）旋转。
- **Roll (翻滚)**: 绕物体**更新的**Z轴（经过Yaw和Pitch旋转后的Z轴）旋转。


**旋转矩阵 (Rotation Matrices)**: 3x3的正交矩阵。无万向锁问题，但有9个参数，其中只有3个自由度，存在冗余，且直接优化9个参数并保持其正交性也比较复杂。

-**轴-角表示法 (Axis-Angle)**: 用一个旋转轴（单位向量）和一个旋转角度来表示。比较紧凑，但插值和组合旋转不如四元数方便。

**四元数 (Quaternions)**: 一种扩展复数的数学概念，由一个实部和三个虚部组成，通常表示为 q=w+xi+yj+zk 或向量形式 [w,x,y,z]。

### ==为何要分成两个参数：==
直接优化协方差矩阵的元素很困难，因为需要保证其物理上的有效性（即半正定性）。梯度下降等优化算法很难直接施加这样的约束，很容易产生无效的协方差矩阵。


## 第二次学习记录

### self.denom = torch.empty(0)
- **含义**: `denom` 是 "denominator"（分母）的缩写。它是一个计数器，与 `xyz_gradient_accum` (梯度累加器) 配套使用。
    
- **作用**: 在训练过程中，每当一个高斯球对最终图像的某个像素有贡献时，它的位置梯度就会被累加到 `xyz_gradient_accum` 中，同时它的 `denom` 计数器就会加 1。
- 
    
- **目的**: 为了计算**平均梯度**。论文中提到，致密化（densification）的依据是“视空间位置梯度的平均幅度” (average magnitude of view-space position gradients) 。如果只看梯度的总和，那么一个经常被看到的、位置合适的高斯球可能会因为累加次数多而产生很高的总梯度，这会带来误判。因此，用总梯度
    
    `xyz_gradient_accum` 除以被看到的次数 `denom`，得到平均梯度 `grads = self.xyz_gradient_accum / self.denom`，才能更准确地判断这个高斯球所在区域是否真的需要被“致密化”。
### self.optimizer = None
- **含义**: 这是PyTorch中的优化器对象。
    
- **作用**: 优化器的任务是在每次反向传播计算出梯度后，根据自身的优化算法（例如Adam）来更新模型的所有可学习参数（如 `_xyz`, `_scaling` 等）。
    
- **为什么初始为`None`**: 在`__init__`阶段，模型框架刚刚搭建好，但还没有从点云加载任何实际的高斯球数据，所有参数张量都是空的。优化器需要绑定到具体的参数上才能工作，因此不能在此时创建。它会在后续的`training_setup`函数中，当所有参数都从点云初始化完毕后，才被正式创建和赋值。

### self.percent_dense = 0
- **含义**: 这个参数是用来区分“小”高斯球和“大”高斯球的一个阈值因子。它在`training_setup`函数中会被赋予一个来自训练参数的实际值。
    
- **作用**: 它是实现论文中两种不同致密化策略的关键。论文提到，对于“欠重建”区域的小高斯球，采用**克隆（Clone）** 策略；对于“过重建”区域的大高斯球，采用**分裂（Split）** 策略 。z
- **==作用二==**：限制大致限制高斯球的大小
    
- **如何工作**:
    
    - 在`densify_and_clone`中，只有尺寸**小于** `percent_dense * scene_extent` 的高斯球才会被考虑克隆。
        
    - 在`densify_and_split`中，只有尺寸**大于** `percent_dense * scene_extent` 的高斯球才会被考虑分裂。 `scene_extent`是整个场景的大致范围，所以这个参数实际上是根据高斯球尺寸相对于整个场景的比例来做判断的

### self.spatial_lr_scale = 0
- **含义**: “空间学习率缩放因子” (Spatial Learning Rate Scale)。
    
- **作用**: 这是一个专门用来调整高斯球**位置（xyz）学习率**的缩放系数。
    
- **目的**: 允许独立控制高斯球“移动快慢”（位置变化）和其他属性“变化快慢”（如颜色、形状、透明度变化）。在`training_setup`中设置优化器时，位置参数`_xyz`的学习率会乘以这个缩放因子：`training_args.position_lr_init * self.spatial_lr_scale`。这非常有用，因为在一些非常大的场景中，如果位置学习率过高，高斯球在训练初期可能会移动得过快，导致不稳定。通过这个缩放因子，可以根据场景的大小来适当调整位置学习率，以保证训练的稳定性和收敛效果 。


## 第三次学习记录
今天主要侧重于进行透明度筛选
设置了一个筛选掉低透明度的方法，但是总体感觉效果一般

#### train.py

- 过滤掉颜色接近黑色的高斯点   错误
```
print(gaussians.colors)
valid_points = torch.any(gaussians.colors > 0.1, dim=1)  # 颜色阈值为 0.1，可根据需要调整
gaussians.positions = gaussians.positions[valid_points]
gaussians.colors = gaussians.colors[valid_points]
gaussians.max_radii2D = gaussians.max_radii2D[valid_points]
```
#### __init__.py
- self.densify_until_iter = 1000
- self.sh_degree = 0

